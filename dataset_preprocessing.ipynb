{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Library"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0bad6c1f5b665c2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:38:47.673082600Z",
     "start_time": "2024-01-10T17:38:38.693407400Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow Version and GPU Availability\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:38:47.701097900Z",
     "start_time": "2024-01-10T17:38:47.675849800Z"
    }
   },
   "id": "a4e8df20da651892"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Iris Needle Dataset Mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f4f63020b26d635"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load COCO File Path\n",
    "f = open('dataset/iris_neddle_raw_dataset/train_annotations.coco.json', 'r')\n",
    "data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c90c7741edfb51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define Mask Directory\n",
    "mask_dir = 'dataset/iris_needle_seg_dataset/mask/'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6827cd38b4a9a00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Processing Mask\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "\n",
    "for image in images:\n",
    "    mask = np.zeros((image['height'], image['width']))\n",
    "    for annotation in annotations:\n",
    "        if annotation['image_id'] == image['id']:\n",
    "            seg = annotation['segmentation']\n",
    "            seg = np.array(seg).reshape((-1, 1, 2)).astype(np.int32)\n",
    "            cv2.fillPoly(mask, [seg], 255)\n",
    "    cv2.imwrite(mask_dir + image['file_name'], mask)\n",
    "    print(image['file_name'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "731edf8019fa06af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Cataract Dataset Mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91fbea4a419b6804"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Load COCO File Path\n",
    "f = open('datasets/classification_datasets/cataract_dataset_raw/550_coco_imglab.json', 'r')\n",
    "data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:25:41.690560600Z",
     "start_time": "2023-11-30T16:25:41.632230500Z"
    }
   },
   "id": "4ccf2ec16f06cba7"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Define Mask Directory\n",
    "mask_dir = 'datasets/classification_datasets/cataract_dataset_segmented/mask/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:25:42.310170500Z",
     "start_time": "2023-11-30T16:25:42.290000300Z"
    }
   },
   "id": "1cfb903976637fb2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal_1.JPG\n",
      "normal_10.JPG\n",
      "normal_100.jpg\n",
      "normal_101.jpg\n",
      "normal_102.jpg\n",
      "normal_103.jpg\n",
      "normal_104.jpg\n",
      "normal_105.jpg\n",
      "normal_106.jpg\n",
      "normal_107.jpg\n",
      "normal_108.jpg\n",
      "normal_109.jpg\n",
      "normal_11.JPG\n",
      "normal_110.jpg\n",
      "normal_111.jpg\n",
      "normal_112.jpg\n",
      "normal_113.JPG\n",
      "normal_114.JPG\n",
      "normal_115.JPG\n",
      "normal_116.JPG\n",
      "normal_117.JPG\n",
      "normal_118.JPG\n",
      "normal_119.JPG\n",
      "normal_12.JPG\n",
      "normal_120.JPG\n",
      "normal_121.JPG\n",
      "normal_122.JPG\n",
      "normal_123.JPG\n",
      "normal_124.JPG\n",
      "normal_125.JPG\n",
      "normal_126.JPG\n",
      "normal_127.JPG\n",
      "normal_128.JPG\n",
      "normal_129.JPG\n",
      "normal_13.JPG\n",
      "normal_130.JPG\n",
      "normal_131.JPG\n",
      "normal_133.JPG\n",
      "normal_132.JPG\n",
      "normal_134.JPG\n",
      "normal_135.JPG\n",
      "normal_136.JPG\n",
      "normal_137.JPG\n",
      "normal_138.JPG\n",
      "normal_139.JPG\n",
      "normal_14.JPG\n",
      "normal_140.JPG\n",
      "normal_141.JPG\n",
      "normal_142.JPG\n",
      "normal_143.JPG\n",
      "normal_144.JPG\n",
      "normal_145.JPG\n",
      "normal_146.JPG\n",
      "normal_147.JPG\n",
      "normal_148.JPG\n",
      "normal_149.JPG\n",
      "normal_15.JPG\n",
      "normal_150.JPG\n",
      "normal_151.JPG\n",
      "normal_152.JPG\n",
      "normal_153.JPG\n",
      "normal_154.JPG\n",
      "normal_156.JPG\n",
      "normal_155.JPG\n",
      "normal_157.JPG\n",
      "normal_158.JPG\n",
      "normal_159.JPG\n",
      "normal_16.JPG\n",
      "normal_160.JPG\n",
      "normal_161.JPG\n",
      "normal_162.JPG\n",
      "normal_163.JPG\n",
      "normal_164.JPG\n",
      "normal_165.JPG\n",
      "normal_166.JPG\n",
      "normal_18.JPG\n",
      "normal_17.JPG\n",
      "normal_19.JPG\n",
      "normal_2.JPG\n",
      "normal_20.JPG\n",
      "normal_21.JPG\n",
      "normal_22.JPG\n",
      "normal_23.JPG\n",
      "normal_24.JPG\n",
      "normal_25.JPG\n",
      "normal_26.JPG\n",
      "normal_28.JPG\n",
      "normal_27.JPG\n",
      "normal_29.JPG\n",
      "normal_3.JPG\n",
      "normal_30.JPG\n",
      "normal_31.JPG\n",
      "normal_34.JPG\n",
      "normal_32.JPG\n",
      "normal_33.JPG\n",
      "normal_35.JPG\n",
      "normal_36.JPG\n",
      "normal_37.JPG\n",
      "normal_38.JPG\n",
      "normal_39.JPG\n",
      "normal_4.JPG\n",
      "normal_40.JPG\n",
      "normal_41.JPG\n",
      "normal_42.JPG\n",
      "normal_43.JPG\n",
      "normal_44.JPG\n",
      "normal_45.JPG\n",
      "normal_46.JPG\n",
      "normal_47.JPG\n",
      "normal_48.JPG\n",
      "normal_49.jpg\n",
      "normal_5.JPG\n",
      "normal_50.jpg\n",
      "normal_51.jpg\n",
      "normal_52.jpg\n",
      "normal_53.jpg\n",
      "normal_54.jpg\n",
      "normal_55.jpg\n",
      "normal_56.jpg\n",
      "normal_57.jpg\n",
      "normal_58.jpg\n",
      "normal_59.jpg\n",
      "normal_6.JPG\n",
      "normal_60.jpg\n",
      "normal_61.jpg\n",
      "normal_62.jpg\n",
      "normal_63.jpg\n",
      "normal_64.jpg\n",
      "normal_65.jpg\n",
      "normal_66.jpg\n",
      "normal_67.jpg\n",
      "normal_68.jpg\n",
      "normal_69.jpg\n",
      "normal_7.JPG\n",
      "normal_70.jpg\n",
      "normal_71.jpg\n",
      "normal_72.jpg\n",
      "normal_73.jpg\n",
      "normal_74.jpg\n",
      "normal_75.jpg\n",
      "normal_76.jpg\n",
      "normal_77.jpg\n",
      "normal_78.jpg\n",
      "normal_79.jpg\n",
      "normal_8.JPG\n",
      "normal_80.jpg\n",
      "normal_81.jpg\n",
      "normal_82.jpg\n",
      "normal_83.jpg\n",
      "normal_84.jpg\n",
      "normal_85.jpg\n",
      "normal_86.jpg\n",
      "normal_87.jpg\n",
      "normal_88.jpg\n",
      "normal_89.jpg\n",
      "normal_9.JPG\n",
      "normal_90.jpg\n",
      "normal_91.jpg\n",
      "normal_92.jpg\n",
      "normal_93.jpg\n",
      "normal_94.jpg\n",
      "normal_95.jpg\n",
      "normal_96.jpg\n",
      "normal_97.jpg\n",
      "normal_98.jpg\n",
      "normal_99.jpg\n",
      "mild_1.jpg\n",
      "mild_10.jpg\n",
      "mild_100.jpg\n",
      "mild_101.jpg\n",
      "mild_102.jpg\n",
      "mild_103.jpg\n",
      "mild_104.jpg\n",
      "mild_105.jpg\n",
      "mild_106.jpg\n",
      "mild_107.jpg\n",
      "mild_108.jpg\n",
      "mild_109.jpg\n",
      "mild_11.jpg\n",
      "mild_110.jpg\n",
      "mild_111.jpg\n",
      "mild_112.jpg\n",
      "mild_113.jpg\n",
      "mild_114.jpg\n",
      "mild_115.jpg\n",
      "mild_116.jpg\n",
      "mild_117.jpg\n",
      "mild_118.jpg\n",
      "mild_119.jpg\n",
      "mild_12.jpg\n",
      "mild_120.jpg\n",
      "mild_121.jpg\n",
      "mild_122.jpg\n",
      "mild_123.jpg\n",
      "mild_124.jpg\n",
      "mild_126.jpg\n",
      "mild_127.jpg\n",
      "mild_125.jpg\n",
      "mild_128.jpg\n",
      "mild_13.jpg\n",
      "mild_129.jpg\n",
      "mild_130.jpg\n",
      "mild_132.jpg\n",
      "mild_133.jpg\n",
      "mild_131.jpg\n",
      "mild_134.jpg\n",
      "mild_135.jpg\n",
      "mild_136.jpg\n",
      "mild_137.jpg\n",
      "mild_138.jpg\n",
      "mild_139.jpg\n",
      "mild_14.jpg\n",
      "mild_140.jpg\n",
      "mild_141.jpg\n",
      "mild_142.jpg\n",
      "mild_143.jpg\n",
      "mild_144.jpg\n",
      "mild_145.jpg\n",
      "mild_148.jpg\n",
      "mild_146.jpg\n",
      "mild_149.jpg\n",
      "mild_15.jpg\n",
      "mild_150.jpg\n",
      "mild_151.jpg\n",
      "mild_153.jpg\n",
      "mild_152.jpg\n",
      "mild_154.jpg\n",
      "mild_155.jpg\n",
      "mild_156.jpg\n",
      "mild_157.jpg\n",
      "mild_158.jpg\n",
      "mild_159.jpg\n",
      "mild_16.jpg\n",
      "mild_160.jpg\n",
      "mild_161.jpg\n",
      "mild_162.jpg\n",
      "mild_163.jpg\n",
      "mild_164.jpg\n",
      "mild_165.jpg\n",
      "mild_166.jpg\n",
      "mild_167.jpg\n",
      "mild_168.jpg\n",
      "mild_169.jpg\n",
      "mild_17.jpg\n",
      "mild_170.jpg\n",
      "mild_171.jpg\n",
      "mild_172.jpg\n",
      "mild_173.jpg\n",
      "mild_174.jpg\n",
      "mild_175.jpg\n",
      "mild_176.jpg\n",
      "mild_177.jpg\n",
      "mild_178.jpg\n",
      "mild_179.jpg\n",
      "mild_147.jpg\n",
      "mild_18.jpg\n",
      "mild_180.jpg\n",
      "mild_181.jpg\n",
      "mild_182.jpg\n",
      "mild_183.jpg\n",
      "mild_184.jpg\n",
      "mild_185.jpg\n",
      "mild_187.jpg\n",
      "mild_188.jpg\n",
      "mild_186.jpg\n",
      "mild_189.jpg\n",
      "mild_19.jpg\n",
      "mild_190.jpg\n",
      "mild_191.jpg\n",
      "mild_192.jpg\n",
      "mild_193.jpg\n",
      "mild_194.jpg\n",
      "mild_195.jpg\n",
      "mild_196.jpg\n",
      "mild_197.jpg\n",
      "mild_198.jpg\n",
      "mild_199.jpg\n",
      "mild_2.jpg\n",
      "mild_20.jpg\n",
      "mild_200.jpg\n",
      "mild_201.jpg\n",
      "mild_202.jpg\n",
      "mild_203.jpg\n",
      "mild_204.jpg\n",
      "mild_205.jpg\n",
      "mild_206.jpg\n",
      "mild_207.jpg\n",
      "mild_208.jpg\n",
      "mild_209.jpg\n",
      "mild_21.jpg\n",
      "mild_210.jpg\n",
      "mild_211.jpg\n",
      "mild_212.jpg\n",
      "mild_213.jpg\n",
      "mild_214.jpg\n",
      "mild_215.jpg\n",
      "mild_216.jpg\n",
      "mild_217.jpg\n",
      "mild_218.jpg\n",
      "mild_219.jpg\n",
      "mild_22.jpg\n",
      "mild_220.jpg\n",
      "mild_23.jpg\n",
      "mild_24.jpg\n",
      "mild_25.jpg\n",
      "mild_26.jpg\n",
      "mild_27.jpg\n",
      "mild_28.jpg\n",
      "mild_29.jpg\n",
      "mild_3.jpg\n",
      "mild_30.jpg\n",
      "mild_31.jpg\n",
      "mild_32.jpg\n",
      "mild_33.jpg\n",
      "mild_34.jpg\n",
      "mild_35.jpg\n",
      "mild_36.jpg\n",
      "mild_37.jpg\n",
      "mild_38.jpg\n",
      "mild_39.jpg\n",
      "mild_4.jpg\n",
      "mild_40.jpg\n",
      "mild_41.jpg\n",
      "mild_42.jpg\n",
      "mild_43.jpg\n",
      "mild_44.jpg\n",
      "mild_45.jpg\n",
      "mild_46.jpg\n",
      "mild_47.jpg\n",
      "mild_48.jpg\n",
      "mild_49.jpg\n",
      "mild_5.jpg\n",
      "mild_50.jpg\n",
      "mild_51.jpg\n",
      "mild_52.jpg\n",
      "mild_53.jpg\n",
      "mild_54.jpg\n",
      "mild_55.jpg\n",
      "mild_56.jpg\n",
      "mild_57.jpg\n",
      "mild_58.jpg\n",
      "mild_59.jpg\n",
      "mild_6.jpg\n",
      "mild_60.jpg\n",
      "mild_61.jpg\n",
      "mild_62.jpg\n",
      "mild_63.jpg\n",
      "mild_64.jpg\n",
      "mild_65.jpg\n",
      "mild_66.jpg\n",
      "mild_67.jpg\n",
      "mild_68.jpg\n",
      "mild_69.jpg\n",
      "mild_7.jpg\n",
      "mild_70.jpg\n",
      "mild_71.jpg\n",
      "mild_72.jpg\n",
      "mild_73.jpg\n",
      "mild_74.jpg\n",
      "mild_75.jpg\n",
      "mild_76.jpg\n",
      "mild_77.jpg\n",
      "mild_78.jpg\n",
      "mild_79.jpg\n",
      "mild_8.jpg\n",
      "mild_80.jpg\n",
      "mild_81.jpg\n",
      "mild_82.jpg\n",
      "mild_83.jpg\n",
      "mild_84.jpg\n",
      "mild_85.jpg\n",
      "mild_86.jpg\n",
      "mild_87.jpg\n",
      "mild_88.jpg\n",
      "mild_89.jpg\n",
      "mild_9.jpg\n",
      "mild_90.jpg\n",
      "mild_91.jpg\n",
      "mild_92.jpg\n",
      "mild_93.jpg\n",
      "mild_94.jpg\n",
      "mild_95.jpg\n",
      "mild_96.jpg\n",
      "mild_97.jpg\n",
      "mild_98.jpg\n",
      "mild_99.jpg\n",
      "severe_1.jpg\n",
      "severe_10.jpg\n",
      "severe_100.jpg\n",
      "severe_101.jpg\n",
      "severe_102.jpg\n",
      "severe_103.jpg\n",
      "severe_104.jpg\n",
      "severe_105.jpg\n",
      "severe_106.jpg\n",
      "severe_107.jpg\n",
      "severe_108.jpg\n",
      "severe_109.jpg\n",
      "severe_11.jpg\n",
      "severe_110.jpg\n",
      "severe_113.jpg\n",
      "severe_114.jpg\n",
      "severe_115.jpg\n",
      "severe_116.jpg\n",
      "severe_117.jpg\n",
      "severe_118.jpg\n",
      "severe_119.jpg\n",
      "severe_12.jpg\n",
      "severe_121.jpg\n",
      "severe_120.jpg\n",
      "severe_122.jpg\n",
      "severe_123.jpg\n",
      "severe_124.jpg\n",
      "severe_125.jpg\n",
      "severe_126.jpg\n",
      "severe_127.jpg\n",
      "severe_128.jpg\n",
      "severe_129.jpg\n",
      "severe_130.jpg\n",
      "severe_13.jpg\n",
      "severe_131.jpg\n",
      "severe_132.jpg\n",
      "severe_133.jpg\n",
      "severe_134.jpg\n",
      "severe_135.jpg\n",
      "severe_136.jpg\n",
      "severe_137.jpg\n",
      "severe_138.jpg\n",
      "severe_139.jpg\n",
      "severe_14.jpg\n",
      "severe_140.jpg\n",
      "severe_141.jpg\n",
      "severe_142.jpg\n",
      "severe_143.jpg\n",
      "severe_144.jpg\n",
      "severe_145.jpg\n",
      "severe_146.jpg\n",
      "severe_148.jpg\n",
      "severe_147.jpg\n",
      "severe_149.jpg\n",
      "severe_15.jpg\n",
      "severe_150.jpg\n",
      "severe_151.jpg\n",
      "severe_152.jpg\n",
      "severe_153.jpg\n",
      "severe_154.jpg\n",
      "severe_155.jpg\n",
      "severe_156.jpg\n",
      "severe_157.jpg\n",
      "severe_158.jpg\n",
      "severe_159.jpg\n",
      "severe_16.jpg\n",
      "severe_160.jpg\n",
      "severe_161.jpg\n",
      "severe_162.jpg\n",
      "severe_163.jpg\n",
      "severe_164.jpg\n",
      "severe_165.jpg\n",
      "severe_166.jpg\n",
      "severe_17.jpg\n",
      "severe_18.jpg\n",
      "severe_19.jpg\n",
      "severe_2.jpg\n",
      "severe_20.jpg\n",
      "severe_21.jpg\n",
      "severe_23.jpg\n",
      "severe_22.jpg\n",
      "severe_24.jpg\n",
      "severe_25.jpg\n",
      "severe_26.jpg\n",
      "severe_27.jpg\n",
      "severe_28.jpg\n",
      "severe_29.jpg\n",
      "severe_3.jpg\n",
      "severe_30.jpg\n",
      "severe_31.jpg\n",
      "severe_32.jpg\n",
      "severe_33.jpg\n",
      "severe_34.jpg\n",
      "severe_35.jpg\n",
      "severe_36.jpg\n",
      "severe_37.jpg\n",
      "severe_38.jpg\n",
      "severe_39.jpg\n",
      "severe_4.jpg\n",
      "severe_40.jpg\n",
      "severe_41.jpg\n",
      "severe_42.jpg\n",
      "severe_43.jpg\n",
      "severe_44.jpg\n",
      "severe_45.jpg\n",
      "severe_46.jpg\n",
      "severe_47.jpg\n",
      "severe_48.jpg\n",
      "severe_49.jpg\n",
      "severe_5.jpg\n",
      "severe_50.jpg\n",
      "severe_51.jpg\n",
      "severe_52.jpg\n",
      "severe_53.jpg\n",
      "severe_54.jpg\n",
      "severe_55.jpg\n",
      "severe_56.jpg\n",
      "severe_57.jpg\n",
      "severe_58.jpg\n",
      "severe_59.jpg\n",
      "severe_6.jpg\n",
      "severe_60.jpg\n",
      "severe_61.jpg\n",
      "severe_62.jpg\n",
      "severe_63.jpg\n",
      "severe_64.jpg\n",
      "severe_65.jpg\n",
      "severe_66.jpg\n",
      "severe_67.jpg\n",
      "severe_68.jpg\n",
      "severe_69.jpg\n",
      "severe_7.jpg\n",
      "severe_70.jpg\n",
      "severe_71.jpg\n",
      "severe_72.jpg\n",
      "severe_73.jpg\n",
      "severe_74.jpg\n",
      "severe_75.jpg\n",
      "severe_76.jpg\n",
      "severe_77.jpg\n",
      "severe_78.jpg\n",
      "severe_79.jpg\n",
      "severe_8.jpg\n",
      "severe_80.jpg\n",
      "severe_81.jpg\n",
      "severe_82.jpg\n",
      "severe_83.jpg\n",
      "severe_84.jpg\n",
      "severe_85.jpg\n",
      "severe_86.jpg\n",
      "severe_87.jpg\n",
      "severe_88.jpg\n",
      "severe_89.jpg\n",
      "severe_9.jpg\n",
      "severe_90.jpg\n",
      "severe_91.jpg\n",
      "severe_92.jpg\n",
      "severe_93.jpg\n",
      "severe_94.jpg\n",
      "severe_95.jpg\n",
      "severe_96.jpg\n",
      "severe_97.jpg\n",
      "severe_98.jpg\n",
      "severe_99.jpg\n"
     ]
    }
   ],
   "source": [
    "# Processing Mask\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "\n",
    "for image in images:\n",
    "    mask = np.zeros((image['height'], image['width']))\n",
    "    for annotation in annotations:\n",
    "        if annotation['image_id'] == image['id']:\n",
    "            seg = annotation['segmentation']\n",
    "            seg = np.array(seg).reshape((-1, 1, 2)).astype(np.int32)\n",
    "            cv2.fillPoly(mask, [seg], 255)\n",
    "    if image['file_name'].endswith('.png'):\n",
    "        image['file_name'] = image['file_name'].replace('.png', '.jpg')\n",
    "    cv2.imwrite(mask_dir + image['file_name'], mask)\n",
    "    print(image['file_name'])\n",
    "\n",
    "with open('550_coco_imglab_fixed.json', 'w') as json_file:\n",
    "    json.dump(data, json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:25:43.517384600Z",
     "start_time": "2023-11-30T16:25:42.856974400Z"
    }
   },
   "id": "eea4bffbbe40ca2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bitwise Operation for Mask Cataract Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4d4dc5c50e51a62"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "datasets/classification_datasets/cataract_dataset_segmented/original/mild_10.png\n",
      "550\n",
      "datasets/classification_datasets/cataract_dataset_segmented/mask/mild_10.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "file_names = []\n",
    "for root, dirs, files in os.walk(\"datasets/classification_datasets/cataract_dataset_segmented/original/\"):\n",
    "    for file in files:\n",
    "        image_paths.append(os.path.join(root, file))\n",
    "        file_names.append(file)\n",
    "print(len(image_paths))\n",
    "print(image_paths[1])\n",
    "\n",
    "mask_paths = []\n",
    "for root, dirs, files in os.walk(\"datasets/classification_datasets/cataract_dataset_segmented/mask/\"):\n",
    "    for file in files:\n",
    "        mask_paths.append(os.path.join(root, file))\n",
    "print(len(mask_paths))\n",
    "print(mask_paths[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:29:06.776504700Z",
     "start_time": "2023-11-30T16:29:06.747402300Z"
    }
   },
   "id": "d7a039044e3e9220"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for image, mask, filename in zip(image_paths, mask_paths, file_names):\n",
    "    x = cv2.imread(image)\n",
    "    x_mask = cv2.imread(mask, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    result = cv2.bitwise_and(x, x, mask=x_mask)\n",
    "    \n",
    "    cv2.imwrite(\"datasets/classification_datasets/cataract_dataset_segmented/bitwise/\" + filename, result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T16:29:10.781060400Z",
     "start_time": "2023-11-30T16:29:08.751215200Z"
    }
   },
   "id": "3fb6c4195a8832d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Segmentation for Roboflow Cataract Dataset Using Trained U-Net Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70a3c23bb2407354"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "SEGMENTATION_MODEL_PATH = \"models/segmentation_model_1/tflite/model.tflite\"\n",
    "TEST_PREDICT_DIR = 'datasets/classification_datasets/roboflow_cataract_dataset_raw/train/Normal/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:40:11.071084400Z",
     "start_time": "2024-01-10T17:40:11.037335700Z"
    }
   },
   "id": "6d5a5c9a53d97b2f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Load TF Lite model\n",
    "interpreter_segmentation = tf.lite.Interpreter(SEGMENTATION_MODEL_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:40:11.389617700Z",
     "start_time": "2024-01-10T17:40:11.376171300Z"
    }
   },
   "id": "c6432a91894a7ae8"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Load Predict Image Path\n",
    "image_path = []\n",
    "file_name = []\n",
    "for root, dirs, files in os.walk(TEST_PREDICT_DIR):\n",
    "    for file in files:\n",
    "        path_og = os.path.join(root,file)\n",
    "        image_path.append(path_og)\n",
    "        file_name.append(file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:40:11.820708100Z",
     "start_time": "2024-01-10T17:40:11.797806400Z"
    }
   },
   "id": "ed1e46a502a109cc"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Allocate Tensors for Input and Output of Model\n",
    "interpreter_segmentation.allocate_tensors()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:40:12.257215Z",
     "start_time": "2024-01-10T17:40:12.213864800Z"
    }
   },
   "id": "24d733ed17a508e1"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Get Height and Width of Input Image\n",
    "_, height, width, _ = interpreter_segmentation.get_input_details()[0]['shape']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:40:12.845143900Z",
     "start_time": "2024-01-10T17:40:12.804108100Z"
    }
   },
   "id": "e5b64782c962304a"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Run Inference for Each Image\n",
    "k = 0\n",
    "\n",
    "for path in image_path:\n",
    "    # Load Image from Path and Resize\n",
    "    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (width, height)).astype(np.float32)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    # Add Batch Dimension\n",
    "    input_image = np.expand_dims(image, axis=0)\n",
    "    input_image = np.expand_dims(input_image, axis=-1)\n",
    "    \n",
    "    # Set Input and Invoke Segmentation Model\n",
    "    interpreter_segmentation.set_tensor(interpreter_segmentation.get_input_details()[0]['index'], input_image)\n",
    "    interpreter_segmentation.invoke()\n",
    "    \n",
    "    # Get Output\n",
    "    output_segmentation = np.squeeze(interpreter_segmentation.get_tensor(interpreter_segmentation.get_output_details()[0]['index']))\n",
    "    output_segmentation = np.where(output_segmentation > 0.9, 1, 0).astype(np.uint8)\n",
    "    \n",
    "    # Multiply Image with Mask\n",
    "    multipy_image = cv2.imread(path)\n",
    "    multipy_image = cv2.resize(multipy_image, (width, height))\n",
    "    multipy_image = cv2.bitwise_and(multipy_image, multipy_image, mask=output_segmentation)\n",
    "    multipy_image = cv2.resize(multipy_image, (64, 64))\n",
    "    \n",
    "    # Save Image\n",
    "    cv2.imwrite('datasets/classification_datasets/roboflow_cataract_segmented/normal/' + file_name[k], multipy_image)\n",
    "    \n",
    "    k+=1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T17:40:25.800584600Z",
     "start_time": "2024-01-10T17:40:13.532801200Z"
    }
   },
   "id": "bb7e417cda9f11b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Return Size of Image from Cataract Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f488e731cd79c13d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 100), (85, 85), (97, 97), (93, 93), (89, 89), (69, 69), (81, 81), (73, 73), (77, 77), (53, 53), (61, 61)]\n"
     ]
    }
   ],
   "source": [
    "def get_image_sizes(folder_path):\n",
    "    image_sizes = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img = cv2.imread(os.path.join(folder_path, filename))\n",
    "            if img is not None:\n",
    "                size = img.shape[:2]\n",
    "                if size not in image_sizes:\n",
    "                    image_sizes.append(size)\n",
    "    return image_sizes\n",
    "\n",
    "folder_path = 'datasets/segmentation_datasets/cataract_seg_dataset/mask'\n",
    "print(get_image_sizes(folder_path))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T04:17:29.707655200Z",
     "start_time": "2023-12-14T04:17:29.475789500Z"
    }
   },
   "id": "e19bd0c395be2775"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Red, Green, Blue, and Gray Scale Image from Cataract Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4113f472abb8964"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def save_rgb_channels(file_path):\n",
    "    # Membaca gambar\n",
    "    img = cv2.imread(file_path)\n",
    "    gray_img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Memisahkan channel warna\n",
    "    blue_channel = img[:,:,0]\n",
    "    green_channel = img[:,:,1]\n",
    "    red_channel = img[:,:,2]\n",
    "    \n",
    "    # Buat numpy array untuk menyimpan channel gambar\n",
    "    blue_img = np.zeros((img.shape))\n",
    "    blue_img[:,:,0] = blue_channel\n",
    "    green_img = np.zeros((img.shape))\n",
    "    green_img[:,:,1] = green_channel\n",
    "    red_img = np.zeros((img.shape))\n",
    "    red_img[:,:,2] = red_channel\n",
    "    \n",
    "    # Menyimpan setiap channel dan grayscale ke file\n",
    "    cv2.imwrite('gray_scale.png', gray_img)\n",
    "    cv2.imwrite('red_channel.png', red_img)\n",
    "    cv2.imwrite('green_channel.png', green_img)\n",
    "    cv2.imwrite('blue_channel.png', blue_img)\n",
    "\n",
    "# Ganti 'path_to_your_image' dengan path file gambar Anda\n",
    "save_rgb_channels('datasets/classification_datasets/roboflow_cataract_dataset_raw/train/Normal/1_JPG_jpg.rf.0afb2437ee24207ca96befdf4676819a.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T03:48:32.253584200Z",
     "start_time": "2023-12-18T03:48:32.182184Z"
    }
   },
   "id": "d58b0e7bb58c63a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "53df9eea855ebd4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
